{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_ch_5_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble\n",
        "- algorithm that performs best in dealing with structured data\n",
        "- Bagging : A method of aggregating results by taking multiple bootstrap samples and training each model. (parallel learning)\n",
        "  + Random Forest\n",
        "- Boosting : (sequential learning)\n",
        "  + GBM --> XGBoost --> LightGBM"
      ],
      "metadata": {
        "id": "-g00KPwjmRjY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RG9ZdeZtxK54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "- Create decision trees randomly and make final predictions based on each tree's predictions.\n",
        "  + Classification : Average the probabilities for each class of each tree and uses the class with the highest probability as a prediction.\n",
        "  + Regression : Average the predictions of each tree.\n",
        "- Bootstrap : method of sampling data by permitting duplication in a dataset"
      ],
      "metadata": {
        "id": "ihL8ivBPnwXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "wine = pd.read_csv('https://bit.ly/wine_csv_data')\n",
        "\n",
        "data = wine[['alcohol', 'sugar', 'pH']].to_numpy()\n",
        "target = wine['class'].to_numpy()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_input, test_input, train_target, test_target = train_test_split(\n",
        "    data, target, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "AL04DqjipIcH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
        "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # overfitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBXGgvHBpWmi",
        "outputId": "0cc345e1-9db6-4d5b-f6e4-00e3212c25da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9973541965122431 0.8905151032797809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(train_input, train_target)\n",
        "print(rf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64O5dRpJqOy0",
        "outputId": "36603cc6-05a2-4f30-bb7b-03360580760a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.23167441 0.50039841 0.26792718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- OOB(out of bag) Sample : remaining sample not included in bootstrap sample\n",
        "  + same effect as cross-validation using a verification set"
      ],
      "metadata": {
        "id": "kbAxF_yFuSVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
        "rf.fit(train_input, train_target)\n",
        "print(rf.oob_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hhoLnK7qnEq",
        "outputId": "65b981d1-22bc-41d5-855d-a415cd5825c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8934000384837406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xzdMxGoTxMgL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GBM(Gradient Boosting Machine)\n",
        "- Correct errors in previous trees by using shallow trees.\n",
        "- Adjust the speed (step width) through the learning rate parameter\n",
        "- less likely to overfit but speed is slow"
      ],
      "metadata": {
        "id": "Kc4z82b7n2io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # good fitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBD-NQdytBsn",
        "outputId": "3fd5baff-ad1c-4cb8-bb29-e1c359cceae1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8881086892152563 0.8720430147331015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# n_estimators = 500 (default 100), learning rate = 0.2 (default 0.1)\n",
        "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
        "scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
        "print(np.mean(scores['train_score']), np.mean(scores['test_score'])) # good fitting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLttPPONtZnW",
        "outputId": "0fc03bf2-42cb-4169-d8e6-2c3822a6c9b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9464595437171814 0.8780082549788999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "IdMTCR0ZxOMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overall Flow of ML\n",
        "0. Data preprocessing, EDA, Visualization\n",
        "1. Design the entire flow as a basic model\n",
        "2. compare multiple models with default hyperparameter\n",
        "3. Cross-validation and Hyperparameter tuning\n",
        "4. Repeat the above process until finding the best result"
      ],
      "metadata": {
        "id": "Kw6Jo_Xbn-I2"
      }
    }
  ]
}